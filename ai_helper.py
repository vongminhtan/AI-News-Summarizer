import subprocess
import json
import os
import config

import threading

# Counter ƒë·ªÉ xoay v√≤ng Engine (Round-robin)
_engine_counter = 0
_counter_lock = threading.Lock()

def call_ai_cli(prompt, model=None, engine_override=None):
    """
    H√†m g·ªçi AI t√πy theo c·∫•u h√¨nh (Gemini ho·∫∑c Codex).
    H·ªó tr·ª£ engine_override cho ph√©p √©p lu·ªìng d√πng AI c·ª• th·ªÉ.
    """
    global _engine_counter
    
    engine = engine_override or getattr(config, "AI_ENGINE", "gemini").lower()
    
    if engine == "hybrid":
        with _counter_lock:
            # Xoay v√≤ng gi·ªØa gemini v√† codex
            current_choice = _engine_counter % 2
            _engine_counter += 1
        
        if current_choice == 0:
            res = call_gemini_cli(prompt, model or config.GEMINI_MODEL)
            # N·∫øu Gemini l·ªói (nhi·ªÅu kh·∫£ nƒÉng l√† 429), th·ª≠ fallback sang Codex ngay
            if res is None:
                print("üîÑ Gemini failed/limit, falling back to Codex...")
                return call_codex_cli(prompt, config.CODEX_MODEL)
            return res
        else:
            return call_codex_cli(prompt, config.CODEX_MODEL)
            
    if engine == "codex":
        # N·∫øu d√πng Codex nh∆∞ng model truy·ªÅn v√†o l√† c·ªßa Gemini, √©p sang Codex model
        actual_model = model if model and not model.startswith("gemini") else config.CODEX_MODEL
        return call_codex_cli(prompt, actual_model)
    else:
        return call_gemini_cli(prompt, model or config.GEMINI_MODEL)

def call_gemini_cli(prompt, model="gemini-2.5-pro"):
    """
    Calls the local 'gemini' CLI tool.
    """
    try:
        # ƒê∆∞·ªùng d·∫´n t·ªõi gemini CLI t·ª´ config
        gemini_path = getattr(config, "GEMINI_CLI_PATH", "gemini")
        process = subprocess.Popen(
            [gemini_path, "--model", model, "--output-format", "json"],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding="utf-8"
        )
        
        stdout, stderr = process.communicate(input=prompt)
        
        if process.returncode != 0:
            print(f"‚ùå Gemini CLI Error: {stderr}")
            return None
        
        json_start = stdout.find('{')
        if json_start == -1:
            return None
            
        json_str = stdout[json_start:]
        response_data = json.loads(json_str)
        return response_data.get("response", "")

    except Exception as e:
        print(f"‚ùå L·ªói khi th·ª±c thi Gemini CLI: {e}")
        return None

def call_codex_cli(prompt, model="gpt-5.2"):
    """
    Calls the local 'codex' CLI tool.
    Example: codex exec --model gpt-5.2 --skip-git-repo-check - <<'PROMPT'
    """
    try:
        # ƒê∆∞·ªùng d·∫´n t·ªõi codex CLI t·ª´ config
        codex_path = getattr(config, "CODEX_CLI_PATH", "codex")
        process = subprocess.Popen(
            [codex_path, "exec", "--model", model, "--skip-git-repo-check", "-"],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding="utf-8"
        )
        
        stdout, stderr = process.communicate(input=prompt)
        
        if process.returncode != 0:
            print(f"‚ùå Codex CLI Error: {stderr}")
            return None
        
        # Codex output th∆∞·ªùng c√≥ header v√† footer
        # Ta l·∫•y n·ªôi dung sau d·∫•u g·∫°ch ngang cu·ªëi c√πng ho·∫∑c sau ch·ªØ 'codex'
        lines = stdout.splitlines()
        content_lines = []
        is_content = False
        
        # Logic b√≥c t√°ch: L·∫•y ph·∫ßn text th√¥ ·ªü cu·ªëi (tr∆∞·ªõc ph·∫ßn token used)
        # Ho·∫∑c ƒë∆°n gi·∫£n l√† tr·∫£ v·ªÅ to√†n b·ªô stdout v√† ƒë·ªÉ caller t·ª± parse JSON n·∫øu c·∫ßn.
        # Codex th∆∞·ªùng tr·∫£ v·ªÅ text tr·ª±c ti·∫øp.
        
        # T√¨m d√≤ng 'codex' v√† l·∫•y ph·∫ßn sau ƒë√≥ cho ƒë·∫øn khi th·∫•y 'tokens used'
        for i, line in enumerate(lines):
            if line.strip() == "codex":
                is_content = True
                continue
            if line.strip() == "tokens used":
                break
            if is_content:
                content_lines.append(line)
        
        if not content_lines:
            # N·∫øu kh√¥ng t√¨m th·∫•y format chu·∫©n, l·∫•y 5 d√≤ng cu·ªëi c√πng b·ªè ƒëi 2 d√≤ng cu·ªëi
            return stdout.strip()

        return "\n".join(content_lines).strip()

    except Exception as e:
        print(f"‚ùå L·ªói khi th·ª±c thi Codex CLI: {e}")
        return None
